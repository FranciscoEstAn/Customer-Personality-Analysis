# Segmentaci√≥n de Usuarios mediante Algoritmos No Supervisados

## üîé √çndice

1. [Objetivos](#objetivos)
2. [Introducci√≥n](#introducci√≥n)
3. [Entorno de Trabajo](#Entorno-de-trabajo)
4. [Descripci√≥n del Conjunto de Datos](#descripci√≥n-del-conjunto-de-datos)
5. [Preprocesamiento de Datos](#preprocesamiento-de-datos)
6. [Aplicaci√≥n de Algoritmos de Clustering](#aplicaci√≥n-de-algoritmos-de-clustering)
7. [Visualizaci√≥n y An√°lisis de Resultados](#visualizaci√≥n-y-an√°lisis-de-resultados)
8. [Resumen de Caracter√≠sticas por Cl√∫ster](#resumen-de-caracter√≠sticas-por-cl√∫ster)
9. [Comparaci√≥n entre KMeans y DBSCAN](#comparaci√≥n-entre-kmeans-y-dbscan)
10. [An√°lisis T√©cnico Detallado](#an√°lisis-t√©cnico-detallado)
11. [Conclusiones](#conclusiones)
12. [Recomendaciones](#recomendaciones)
13. [Autores](#autores)

---

## Objetivos

Implementar modelos de aprendizaje no supervisado para identificar segmentos de clientes a partir de sus caracter√≠sticas demogr√°ficas, de consumo y respuesta a campa√±as. Comparar modelos, validar visualmente los resultados y construir perfiles √∫tiles para acciones de marketing personalizadas.

---

## Introducci√≥n

En este proyecto se aplican algoritmos no supervisados como KMeans y DBSCAN sobre un dataset de clientes, con el objetivo de segmentar perfiles de comportamiento y consumo. Se incluyen t√©cnicas como PCA y t-SNE para reducir dimensionalidad y facilitar la visualizaci√≥n de resultados.

---
## Entorno de trabajo: versiones, librer√≠as y herramientas.

### Entorno de Trabajo
- Google Colab Notebook (formato .ipynb)
- ython 3.x
- Ejecuci√≥n basada en entorno de notebook 
________________________________________
### Librer√≠as Importadas
#### Manipulaci√≥n y An√°lisis de Datos:
- **pandas** ‚Äì estructuras tipo DataFrame para manipular datos
- **numpy** ‚Äì operaciones matem√°ticas y manejo de arrays
#### Visualizaci√≥n:
- **matplotlib.pyplot** ‚Äì creaci√≥n de gr√°ficos est√°ticos (l√≠neas, barras, etc.)
- **seaborn** ‚Äì visualizaci√≥n estad√≠stica elegante sobre matplotlib
#### Preprocesamiento y Reducci√≥n de Dimensionalidad:
- **sklearn.preprocessing.StandardScaler** ‚Äì estandarizaci√≥n de variables
- **sklearn.decomposition.PCA** ‚Äì reducci√≥n lineal de dimensionalidad
- **sklearn.manifold.TSNE** ‚Äì reducci√≥n no lineal para visualizaci√≥n avanzada
#### Algoritmos de Clustering:
- **sklearn.cluster.KMeans** ‚Äì clustering particional
- **sklearn.cluster.DBSCAN** ‚Äì clustering basado en densidad
#### M√©tricas y Evaluaci√≥n:
- **sklearn.metrics.silhouette_score** ‚Äì medida de calidad del clustering
- **sklearn.neighbors.NearestNeighbors** ‚Äì an√°lisis de vecinos m√°s cercanos (para estimar eps en DBSCAN)
________________________________________
### Herramientas T√©cnicas Derivadas
- **Gr√°ficas:** codo, silhouette, t-SNE, PCA
- **An√°lisis estad√≠stico:** media, desviaci√≥n est√°ndar, percentiles
- **Visualizaci√≥n exploratoria:** mapas de calor, boxplots
- **Reducci√≥n de dimensionalidad:** PCA y t-SNE para comprensi√≥n visual
- **Evaluaci√≥n del modelo:** coeficiente de Silhouette y visualizaci√≥n de clusters

---

## Descripci√≥n del Conjunto de Datos

El dataset contiene 2,240 registros y 29 variables, agrupadas en:
- **Demograf√≠a:** A√±o de nacimiento, educaci√≥n, estado civil, ingresos, hijos en el hogar.
- **Comportamiento de compra:** Gastos en distintas categor√≠as (vino, carnes, dulces...).
- **Campa√±as de marketing:** Aceptaci√≥n de campa√±as, respuesta general.
- **Canales de compra:** Compras en web, cat√°logo, tienda, visitas al sitio.

Este conjunto permite analizar tanto el perfil socioecon√≥mico como el comportamiento transaccional y la respuesta a est√≠mulos comerciales.

---

## An√°lisis T√©cnico
### Preprocesamiento de Datos

- Se eliminaron columnas no informativas (ID, fechas, costos fijos).
- Las variables categ√≥ricas fueron convertidas a dummies.
- Se estandariz√≥ el conjunto con `StandardScaler`.
- Se imputaron valores nulos.
- Se agreg√≥ una columna de edad calculada y otras m√©tricas agregadas.

Este preprocesamiento asegura que las variables est√©n en la misma escala y que los algoritmos de clustering funcionen correctamente.

---

### Aplicaci√≥n de Algoritmos de Clustering

#### KMeans
Se us√≥ el m√©todo del codo para elegir el n√∫mero √≥ptimo de cl√∫steres, identificado en **K=5**. Se aplic√≥ el algoritmo y se interpretaron los cl√∫steres generados mediante estad√≠stica descriptiva.

#### DBSCAN
DBSCAN no requiere un n√∫mero de cl√∫steres predefinido. Se exploraron diferentes combinaciones de los par√°metros `eps` y `min_samples` mediante la gr√°fica de distancia de vecinos m√°s cercanos.

---

### Visualizaci√≥n y An√°lisis de Resultados

#### Selecci√≥n del N√∫mero √ìptimo de Clusters
Para determinar el n√∫mero √≥ptimo de clusters se utilizaron dos m√©todos: el m√©todo del codo y el coeficiente de Silhouette. El m√©todo del codo eval√∫a la inercia (la suma de los errores cuadr√°ticos dentro de los clusters) y mostr√≥ un punto de inflexi√≥n en K=5, lo que sugiere que a√±adir m√°s clusters no mejora significativamente la segmentaci√≥n. Por otro lado, el coeficiente de Silhouette mide qu√© tan bien est√° un punto dentro de su cluster en comparaci√≥n con otros clusters. Aunque su valor m√°ximo se presenta en K=2, el valor en K=5 tambi√©n fue alto, lo cual valida esta elecci√≥n desde otro enfoque.

#### M√©todo del Codo y Silhouette

![Elbow y Silhouette](Imagenes/elbow_silhouette.png)

Estas gr√°ficas confirman que K=5 ofrece una segmentaci√≥n equilibrada.

### Aplicaci√≥n de Modelos de Clustering y Reducci√≥n de Dimensionalidad
Posteriormente, se procedi√≥ a la aplicaci√≥n de los algoritmos de clustering K-Means y DBSCAN, y se utilizaron t√©cnicas de reducci√≥n de dimensionalidad como PCA y t-SNE para visualizar los resultados. Se generaron proyecciones en dos dimensiones para ambos algoritmos, permitiendo evaluar la coherencia visual de los clusters.

#### Visualizaci√≥n con PCA y t-SNE

![PCA](Imagenes/pca_kmeans.png)
Facilita la reducci√≥n de dimensiones a 2 usando PCA, esto para la visualizaci√≥n.

#### K-Means con t-SNE (Visualizaci√≥n No Lineal)
![t-SNE](Imagenes/tsne_projection.png)

Las visualizaciones obtenidas muestran que el algoritmo K-Means produce agrupaciones sim√©tricas y bien definidas tanto en PCA como en t-SNE. Por su parte, DBSCAN permite identificar agrupaciones m√°s libres y detecta puntos de ruido (outliers), los cuales aparecen dispersos. Con t-SNE se aprecia una mejor separaci√≥n entre clusters, lo que permite visualizar estructuras complejas que PCA no logra capturar completamente.

PCA permite ver una distribuci√≥n lineal. t-SNE expone relaciones no lineales y muestra mejor separaci√≥n entre los cl√∫steres generados por KMeans.



### Visualizaci√≥n Comparativa de Modelos
#### Comparativa entre K-Means y DBSCAN con PCA

![Comparativa](Imagenes/comparativa_pca_kmeans_dbscan.png)

En la parte izquierda de la imagen, K-Means logra separar los datos en cinco agrupaciones bastante diferenciadas. 
Se observa una distribuci√≥n m√°s compacta y organizada, con l√≠mites claros entre los grupos. Por otro lado, DBSCAN (parte derecha) identifica un √∫nico cluster principal y solo unos pocos puntos como ruido (etiquetados como -1). 
Esto indica que, con la configuraci√≥n actual de par√°metros (eps y min_samples), DBSCAN no encuentra estructura suficiente para generar m√∫ltiples grupos significativos en este conjunto de datos escalados.

#### DBSCAN con PCA (zoom para ver ruido)

![DBSCAN con PCA](Imagenes/dbscan_pca.png)

Aqu√≠ se confirma que DBSCAN clasific√≥ a casi todos los puntos dentro de un √∫nico grupo, con solo algunos considerados como ruido. La falta de subdivisi√≥n en varios grupos podr√≠a deberse a una configuraci√≥n de eps demasiado grande o a una baja variabilidad entre los datos tras PCA.


#### k-Distance Plot para DBSCAN

![k-distance](Imagenes/k_distance_plot.png)

Ayuda a seleccionar el `eps` √≥ptimo para DBSCAN. La "rodilla" indica la distancia cr√≠tica.

---

## Resumen de Caracter√≠sticas por Cl√∫ster

Se presentaron estad√≠sticas como media e IQR por grupo. Algunas observaciones:
- Cl√∫ster 0: Ingresos altos, alto gasto en productos premium.
- Cl√∫ster 2: Menor interacci√≥n digital pero buena respuesta a campa√±as.
- DBSCAN agrup√≥ la mayor√≠a en un solo cl√∫ster, √∫til para detecci√≥n de outliers.

Estas caracter√≠sticas permitieron desarrollar perfiles de clientes bien diferenciados.

---

## Comparaci√≥n entre KMeans y DBSCAN

KMeans produjo cl√∫steres m√°s sim√©tricos y balanceados. DBSCAN fue m√°s √∫til para detecci√≥n de ruido y patrones densos sin estructura clara. PCA y t-SNE validaron visualmente las agrupaciones de KMeans, especialmente en espacios no lineales.

---

## An√°lisis T√©cnico Detallado

- El m√©todo del codo detect√≥ que a partir de K=5, la ganancia de informaci√≥n adicional disminuye.
- El coeficiente de Silhouette fue alto para K=5, validando la cohesi√≥n intra-cl√∫ster.
- DBSCAN fue sensible al valor de `eps`. El valor ideal se encontr√≥ cerca de 3.5.
- Visualmente, PCA y t-SNE confirmaron una estructura interna coherente en KMeans.
- Variables clave como `Income`, `MntWines`, `MntGoldProds`, `NumWebPurchases` y `AcceptedCmpX` fueron cruciales para definir los perfiles.

Limitaciones:
- DBSCAN requiere ajuste fino de par√°metros. Un eps mal elegido puede agrupar todo en un cl√∫ster.
- El escalado est√°ndar asigna igual peso a todas las variables, lo que puede no reflejar su importancia real.

---
## AN√ÅLISIS ESTAD√çSTICO
La tabla proporciona estad√≠sticas como la media, desviaci√≥n est√°ndar, m√≠nimo, m√°ximo, cuartiles (25%, 50%, 75%) para las columnas num√©ricas.
A continuaci√≥n, se presenta el an√°lisis estad√≠stico por cl√∫ster. En lugar de usar gr√°ficos como mapas de calor o histogramas, se utilizaron tablas que muestran los valores promedio por grupo.

| Variable            | count |   mean   |   std   | min  | 25%   | 50%   | 75%    | max    |
|:--------------------|------:|---------:|--------:|-----:|------:|------:|-------:|-------:|
| Year_Birth          |  2216 | 1968.82  |  11.99  | 1893 | 1959  | 1970  | 1977   | 1996   |
| Income              |  2216 | 52247.25 | 25173.1 | 1730 | 35303 | 51381 | 68522  | 666666 |
| Kidhome             |  2216 | 0.44     | 0.54    | 0    | 0     | 0     | 1      | 2      |
| Teenhome            |  2216 | 0.50     | 0.54    | 0    | 0     | 0     | 1      | 2      |
| Recency             |  2216 | 49.01    | 28.95   | 0    | 24    | 49    | 74     | 99     |
| MntWines            |  2216 | 305.09   | 337.33  | 0    | 24    | 174.5 | 505    | 1493   |
| MntFruits           |  2216 | 26.36    | 39.79   | 0    | 2     | 8     | 33     | 199    |
| MntMeatProducts     |  2216 | 166.99   | 224.28  | 0    | 16    | 68    | 232.25 | 1725   |
| MntFishProducts     |  2216 | 37.64    | 54.75   | 0    | 3     | 12    | 50     | 259    |
| MntSweetProducts    |  2216 | 27.03    | 41.07   | 0    | 1     | 8     | 33     | 262    |
| MntGoldProds        |  2216 | 43.97    | 51.82   | 0    | 9     | 24.5  | 56     | 321    |
| NumDealsPurchases   |  2216 | 2.32     | 1.92    | 0    | 1     | 2     | 3      | 15     |
| NumWebPurchases     |  2216 | 4.09     | 2.74    | 0    | 2     | 4     | 6      | 27     |
| NumCatalogPurchases |  2216 | 2.67     | 2.93    | 0    | 0     | 2     | 4      | 28     |
| NumStorePurchases   |  2216 | 5.80     | 3.25    | 0    | 3     | 5     | 8      | 13     |
| NumWebVisitsMonth   |  2216 | 5.32     | 2.43    | 0    | 3     | 6     | 7      | 20     |
| AcceptedCmp3        |  2216 | 0.07     | 0.26    | 0    | 0     | 0     | 0      | 1      |
| AcceptedCmp4        |  2216 | 0.07     | 0.26    | 0    | 0     | 0     | 0      | 1      |
| AcceptedCmp5        |  2216 | 0.07     | 0.26    | 0    | 0     | 0     | 0      | 1      |
| AcceptedCmp1        |  2216 | 0.06     | 0.24    | 0    | 0     | 0     | 0      | 1      |
| AcceptedCmp2        |  2216 | 0.01     | 0.12    | 0    | 0     | 0     | 0      | 1      |
| Complain            |  2216 | 0.01     | 0.10    | 0    | 0     | 0     | 0      | 1      |
| Response            |  2216 | 0.15     | 0.36    | 0    | 0     | 0     | 0      | 1      |


## Conclusiones

- KMeans con **K=5** proporciona una segmentaci√≥n robusta, interpretable y √∫til para estrategias comerciales.
- DBSCAN se recomienda como herramienta exploratoria para detecci√≥n de valores at√≠picos.
- Las visualizaciones con t-SNE confirmaron que los grupos de KMeans son estructuralmente v√°lidos.
- La segmentaci√≥n permite dise√±ar campa√±as diferenciadas y mejorar la eficiencia de las acciones de marketing.

---

## Recomendaciones

- Utilizar los segmentos como insumo en sistemas CRM y campa√±as espec√≠ficas.
- Ajustar DBSCAN din√°micamente o aplicar HDBSCAN para mayor granularidad.
- Incorporar an√°lisis de importancia de variables o t√©cnicas de reducci√≥n supervisada.
- Reentrenar el modelo con datos recientes de clientes activos.

---


---

## Autores

Francisco Estupi√±an 
Mar√≠a Fernanda Bola√±os
Fernando Monta√±o  
Proyecto de Segmentaci√≥n de Usuarios - 2025
